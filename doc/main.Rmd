---
title: "Airbnb Listing Optimization Analysis"
author: "Elena Dubova, Max Karsok, Matthew Vitha"
date: "May 1st, 2019"
output: html_document
---

# Step 1: Load required libraries and sources.

```{r libraries, echo = FALSE, warning=FALSE, message=FALSE}

if(!require("dplyr")){
  install.packages("dplyr")}
  library(dplyr)
if(!require("Hmisc")){
  install.packages("Hmisc")}
  library(Hmisc)
if(!require("qdap")){
  install.packages("qdap")}
  library(qdap)
if(!require("magrittr")){
  install.packages("magrittr")}
  library(magrittr)
if(!require("tm")){
  install.packages("tm")}
  library(tm)
if(!require("tidyverse")){
  install.packages("tidyverse")}
  library(tidyverse)
if(!require("tidytext")){
  install.packages("tidytext")}
  library(tidytext)
if(!require("ggplot2")){
  install.packages("ggplot2")}
  library(ggplot2)
if(!require("data.table")){
  install.packages("data.table")}
  library(data.table)
if(!require("wordcloud")){
  install.packages("wordcloud")}
  library(wordcloud)
if(!require("lubridate")){
  install.packages("lubridate")}
  library(lubridate)
if(!require("DT")){
  install.packages("DT")}
  library(DT)
if(!require("stringr")){
  install.packages("stringr")}
  library(stringr)
if(!require("topicmodels")){
  install.packages("topicmodels")}
  library(topicmodels)
if(!require("SnowballC")){
  install.packages("SnowballC")}
  library(SnowballC)
if(!require("classInt")){
  install.packages("classInt")}
  library(classInt)
if(!require("cowplot")){
  install.packages("cowplot")}
  library(cowplot)
if(!require("beeswarm")){
  install.packages("beeswarm")}
  library(beeswarm)
if(!require("rworldmap")){
  install.packages("rworldmap")}
  library(rworldmap)
if(!require("RColorBrewer")){
  install.packages("RColorBrewer")}
  library(RColorBrewer)
if(!require("cowplot")){
  install.packages("cowplot")}
  library(cowplot)
if(!require("ldatuning")){
  install.packages("ldatuning")}
  library(ldatuning)
if(!require("SnowballC")){
  install.packages("SnowballC")}
  library(SnowballC)


source('../lib/tf_idf.R')
source('../lib/lda.R')
source("../lib/get_dtm.R")

```

# Step 2: Read data from working directory.

The original data file is approximately 28 MB in compressed state; therefore we download data locally and read it from directory rather than reading it from the “data” folder. Link to download zip file in located in the README.md file in the data folder of the repository. Alternatively, one can skip **Step 2** and **Step 3** and proceed with cleaned and transformed dataset from **Step 4**.

```{r warning=FALSE, message=FALSE}

path  = "C:/Users/heldo/Desktop/analysisData.csv"
data = read.csv(path, header = TRUE)

```


# Step 3: Feature generation, data selection.

As we are specifically interested in understanding of what makes a successful and unsuccessful listing write up, it is not very efficient to look at all 29,142 observations from the dataset. To extract useful insights, we decided to get rid of listings with "average performance" and come up with two polar samples that present "the best" and "the worst" listings (further defined as "Good" and "Bad"). To measure "goodness" of the listing we created a composite indicator that considers score ratings, two measures of popularity (overall number of reviews and number of last month's reviews), and "super host indicator". To reduce bias in the sample, we controlled for location (simultaneously limiting it to most popular options) and price bucket.

```{r message=FALSE, warning=FALSE}
#EDA needes to obtain stratified sample
hist(data$price, breaks = 100) #distribution of prices help to determine price buckets
```
From this right-skewed disctribution it is interesting to observe that long tail of very expensive apartments.
```{r}
hist(data$reviews_per_month, breaks = 100, xlim = c(0, 10)) #distribution of reviews per month helps set threshold for this indicator
```
This is another right-skewed distribution; Number of Rewies per month above two can be considered as substantially above average, so we choose it as an upper threshold. 

```{r}
plot(data$neighbourhood_group_cleansed) # Brooklyn and Manhattan are reasonable choices to limit to when placing controls over location. 
```
Based on distribution above and intention to control for location and price bucket, we construct the sample to analyse below.

```{r message=FALSE, warning=FALSE}

 # create price brackets #
data$price_bkt <- as.numeric(cut2(data$price, g=4))
 # re-create buroughs field #
data$location_bkt <- data$neighbourhood_group_cleansed
 # create good locations and bad locations based on paramaters #
polar_data <- data %>%
          group_by(id) %>%
          mutate(category = case_when(
                          review_scores_rating >= 87 &
                            reviews_per_month  >= 2 &
                            host_is_superhost  == 't' ~ 'Good',
                          review_scores_rating <= 87 &
                            reviews_per_month  <= 0.5 &
                            host_is_superhost  == 'f' ~ 'Bad')) %>%
          filter(category %in% c('Good', 'Bad')) %>%
          filter(location_bkt %in% c('Manhattan', 'Brooklyn')) %>%
          mutate(strat = case_when(
                        location_bkt == 'Manhattan' & price_bkt == 1 ~ 1,#1 is cheapest 4 is most expensive
                        location_bkt == 'Manhattan' & price_bkt == 2 ~ 2,
                        location_bkt == 'Manhattan' & price_bkt == 3 ~ 3,
                        location_bkt == 'Manhattan' & price_bkt == 4 ~ 4,
                        location_bkt == 'Brooklyn' & price_bkt == 1 ~ 5,
                        location_bkt == 'Brooklyn' & price_bkt == 2 ~ 6,
                        location_bkt == 'Brooklyn' & price_bkt == 3 ~ 7,
                        location_bkt == 'Brooklyn' & price_bkt == 4 ~ 8))

#save(polar_data, file = "../output/stratified_sample.Rdata")

 # stratification outline #
table(polar_data$strat, polar_data$category)
```

# Step 4: Alalysis. 

```{r}

load("../output/stratified_sample.Rdata") #polar_data

```

## 4.1 Length of the textual variables.

```{r message=FALSE, warning=FALSE, paged.print=FALSE}

# calculate the length 
polar_data = polar_data %>% mutate(total_length = nchar(as.character(description))+nchar(as.character(summary))+nchar(as.character(space))+nchar(as.character(neighborhood_overview))+nchar(as.character(notes))+nchar(as.character(transit))+nchar(as.character(access))+nchar(as.character(interaction))+nchar(as.character(house_rules))+nchar(as.character(host_about)))
 # plot #
 ggplot(polar_data, aes(total_length, fill = category)) + geom_histogram() + facet_grid(rows = vars(strat), cols = vars(category)) + ggtitle("Total Lengths of  Listings in Good and Bad Category") + theme(axis.text.x = element_text(size=8),axis.text.y = element_text(size=5))
 
 #ggsave("../figs/total_length_category.png")
 
```

On average, successful listings are longer and it is consistent throughout 8 strata of sample. To be more precise, we can compare means.

```{r}

polar_data %>%
  select(id, category, total_length) %>%
  group_by(category) %>%
  summarise(mean = mean(total_length))

```
So, first free tip for a new host is to invest energy to write more text to describe the apartment. 


```{r}
  # calculate lengths as variables
 polar_data_full = polar_data %>% 
 mutate(description_length = nchar(as.character(description))) %>%
 mutate(space_length = nchar(as.character(space))) %>%
 mutate(neighborhood_overview_length = nchar(as.character(neighborhood_overview))) %>%
 mutate(transit_length = nchar(as.character(transit))) %>%
 mutate(access_length = nchar(as.character(access))) %>%
 mutate(interaction_length = nchar(as.character(interaction))) %>%
 mutate(house_rules_length = nchar(as.character(house_rules))) %>%
 mutate(host_length = nchar(as.character(host_about)))

 # plot

plt1 = ggplot(polar_data_full, aes(description_length, fill = category)) + geom_density(alpha = 0.3) + theme(axis.text.x = element_blank(), axis.text.y = element_blank(),axis.ticks = element_blank(),axis.title.x= element_blank(), legend.position = "none")
plt2 = ggplot(polar_data_full, aes(space_length, fill = category)) + geom_density(alpha = 0.3) + theme(axis.text.x = element_blank(), axis.text.y = element_blank(),axis.ticks = element_blank(),axis.title.x= element_blank(),axis.title.y= element_blank(), legend.position = "none")
plt3 = ggplot(polar_data_full, aes(neighborhood_overview_length, fill = category)) + geom_density(alpha = 0.3) + theme(axis.text.x = element_blank(), axis.text.y = element_blank(),axis.ticks = element_blank(), axis.title.x= element_blank(),axis.title.y= element_blank(),legend.position = "none")
plt4 = ggplot(polar_data_full, aes(transit_length, fill = category)) + geom_density(alpha = 0.3) + theme(axis.text.x = element_blank(), axis.text.y = element_blank(),axis.ticks = element_blank(), axis.title.x= element_blank(),legend.position = "none")
plt5 = ggplot(polar_data_full, aes(access_length, fill = category)) + geom_density(alpha = 0.3) + theme(axis.text.x = element_blank(), axis.text.y = element_blank(),axis.ticks = element_blank(), axis.title.x= element_blank(),axis.title.y= element_blank(),legend.position = "none")
plt6 = ggplot(polar_data_full, aes(interaction_length, fill = category)) + geom_density(alpha = 0.3) + theme(axis.text.x = element_blank(), axis.text.y = element_blank(),axis.ticks = element_blank(), axis.title.x= element_blank(),axis.title.y= element_blank(),legend.position = "none")
plt7 = ggplot(polar_data_full, aes(house_rules_length, fill = category)) + geom_density(alpha = 0.3) + theme(axis.text.x = element_blank(), axis.text.y = element_blank(),axis.ticks = element_blank(),axis.title.x= element_blank(), legend.position = "none")
plt8 = ggplot(polar_data_full, aes(host_length, fill = category)) + geom_density(alpha = 0.3) + theme(axis.text.x = element_blank(), axis.text.y = element_blank(),axis.title.x= element_blank(), axis.title.y= element_blank(),axis.ticks = element_blank())


plot_grid(plt1, plt2, plt3, plt4, plt5, plt6, plt7, plt8, labels = c("Description", "Space", "Neighbourhood", "Transit", "Access", "Interaction", "Rules", "Host"), label_size = 8, label_x = 0.4, scale = 1.1)
#ggsave("../figs/density_length_category.png")
 
```
Observing how much "good" and "bad" hosts write about their listings, we observe same the general trend: successful hosts are more loquacious. It seems that unseccessful hosts underutilise the opportunity to describe their apartment, especially when it comes to - most probably optional - "space", "neighborhood", "transit", "access", "interaction" and "rules" categories. Interestingly, both "good" and "bad" hosts often ignore description of themselves, where we observe very similar disctribution shapes. Another interesting observation is about mandatory field "description": variance is pretty low for "good" listings, especially, comparing to high variance of "bad" listings.
```{r}

ggplot(polar_data_full, aes(category, description_length, fill = category)) + geom_boxplot() 
#ggsave("../figs/description_length_boxplot.png")

```

The boxplot provides clear guidance on how to approach this particular mandatory category: to be successful one should make an effort to write 1000 words. 

```{r message=FALSE, warning=FALSE, paged.print=FALSE}

polar_data_full = polar_data_full %>% 
  mutate(full_text = paste(as.character(description), as.character(summary),as.character(space), as.character(neighborhood_overview),as.character(notes),as.character(transit),as.character(access),as.character(interaction),as.character(house_rules),as.character(host_about)))%>% 
  mutate(num_exclam_interaction = str_count(full_text, "!"))

ggplot(polar_data_full, aes(num_exclam_interaction, fill = category)) + geom_density(alpha = 0.3) + theme(axis.text.x = element_blank(), axis.text.y = element_blank(), axis.ticks = element_blank()) + scale_x_log10() + ggtitle("A Quick Note about Exclamation Marks")

#ggsave("../figs/density_exclamation_marks.png")

```

We observe slightly higher tendency to add emotion to the listing utilizing most straightforward tool - exclamation marks in the cohort of "good" hosts. However, the difference between groups is insignificant. So, there is no evidence that exclamation marks signal successful or unsuccessful listing. So, not tip here other than keeping it reasonable. 

## 4.2 LDA topic modeling contrasting the two categories.

It is interesting to what extent narrative differs for successful and unsucessful listings. We have to treat "good" and "bad" listings separately as we compose a document-term matrix and derive insightful topics. 

First, we look into topics of rather unsuccessful narratives.

```{r}
polar_data_full_bad = polar_data_full %>% filter(category == "Bad")

polar_data_full_bad_text = paste(unlist(polar_data_full_bad$full_text), collapse =" ")
```

```{r}

corpus_bad = getCorpus(polar_data_full_bad_text)
tm_map(corpus_bad, stemDocument)
dtm_bad = DocumentTermMatrix(corpus_bad)
stat_best_bad = FindTopicsNumber(dtm_bad, topics = seq(from = 2, to = 15, by = 1),metrics = c("Griffiths2004", "CaoJuan2009", "Arun2010", "Deveaud2014"), method = "Gibbs", control = list(seed = 2019), mc.cores = 2L, verbose = TRUE)

save(stat_best_bad, file = "../output/LDA_topic_number_bad.Rdata")

FindTopicsNumber_plot(stat_best_bad)
#ggsave("../figs/best_number_topics_bad.png")
```

For "bad" listings optimal number of topics is 3. 

```{r message=FALSE, warning=FALSE, paged.print=FALSE}

top_terms_by_topic_LDA(polar_data_full_bad_text, plot = T, number_of_topics = 3)
#ggsave("../figs/lda_bad.png")

```
With a share of speculation, we can summarize least favorable topics: (1) featuring Williamsburg, Brooklyn with emphasis on size of apartment, proximity to the station, restaurants and coffeshops; (2) featuring Manhattan, with emphasis on kitchen and proximity to the city and the park (indeed, last popular thing on Manhattan is to cook); (3) walking distance to bars and shops also does not signal a successful description.

Now, we do the same exercise for "good" listings.
```{r}
polar_data_full_good = polar_data_full %>% filter(category == "Good")

polar_data_full_good_text = paste(unlist(polar_data_full_good$full_text), collapse =" ")
```

```{r}
 
corpus_good = getCorpus(polar_data_full_good_text)
tm_map(corpus_good, stemDocument)
dtm_good = DocumentTermMatrix(corpus_good)
stat_best_good = FindTopicsNumber(dtm_good, topics = seq(from = 2, to = 15, by = 1),metrics = c("Griffiths2004", "CaoJuan2009", "Arun2010", "Deveaud2014"), method = "Gibbs", control = list(seed = 2019), mc.cores = 2L, verbose = TRUE)

save(stat_best_good, file = "../output/LDA_topic_number_good.Rdata")

FindTopicsNumber_plot(stat_best_good)
#ggsave("../figs/best_number_topics_good.png")
```
For "good" listings optimal number of topics is also 3. General behavior of the graphs is similar. It just can be noted that Griffiths's method proposes higher topic variability for "good" hosts. 

```{r message=FALSE, warning=FALSE, paged.print=FALSE}

top_terms_by_topic_LDA(polar_data_full_good_text, plot = T, number_of_topics = 3)
#ggsave("../figs/lda_good.png")

```

Here, summary fo the topics may be the following: (1) combination on space, floor and convinient logistics; (2) apartment for family with storage space, featuring modern look and bathroom; (3) a fusion from "bad" scenarios: Manhattan and Brooklyn neighborhoods, restaurants and kitchen, as well as logistical benefits. Especially in he last topic, there is a noticable overlap between narratives from "good" and "bad" listings. We paid attention to several distinct features found only in "good" lsitings: 
* reference to how guests "feel";
* reference to "family"
* openness to "questions".

"Bathroom" is a leading word for a "good topic", mentioning "kitchen" is controversial. 

## 4.3 TD_IDF Analysis of Categories.

Analysis is performed on 'summary' data.

```{r message=FALSE, warning=FALSE}
polar_data_full$summary = as.character(
polar_data_full$summary)
polar_data_full_summary = polar_data_full%>% select(summary, category)

top_terms_by_topic_tfidf(polar_data_full_summary, summary, category, plot = T)

ggsave("../figs/td_idf_good_summary.png")

```
Next tip from term frequency/inverse document frequency analysis: for a successful write up use standard keyboard, practice proper English language, mention social clues (such as membership and charity) and fancy notions (such as "manor" instead of, say, "house"). 

## 4.4 Sentiment Analysis.

Finally, it is useful to look into how successful and unsuccessful hosts use sentiment in their listings. 


```{r}

dtm_good <- get.dtm(polar_data_full_good$full_text)
dtm_matrix_good = as.matrix(dtm_good)
dim(dtm_matrix_good)
tidy_format_good = tidy(dtm_good)

```
```{r}
dtm_bad <- get.dtm(polar_data_full_bad$full_text)
dtm_matrix_bad = as.matrix(dtm_bad)
dim(dtm_matrix_bad)

tidy_format_bad = tidy(dtm_bad)
```
It is important to mention that sample size is similar, as sentiment analysis is based on counts. Amount of "bad" listings in analysis even slighly bigger.

We considered nrc classification for sentiment analysis. 

```{r}
data(sentiments)
nrc = subset(sentiments, sentiments$lexicon == 'nrc')
```

Here we can see how "good" and "bad" listings differ in terms of "positive" and "negative" sentiment.

```{r}
plutchik_good = tidy_format_good %>% 
  inner_join(nrc, by = c("term" = "word")) %>% 
  filter(sentiment %in% c("positive", "negative")) %>%
  group_by(sentiment) %>%
  summarise(total_count = sum(count))

plutchik_good_plot = ggplot(plutchik_good, aes(sentiment, total_count, fill = sentiment))+ geom_bar(stat = "identity") + ylim(0, 80000) +  theme(axis.title.x = element_blank(), axis.title.y= element_blank(),legend.position = "none")

plutchik_bad = tidy_format_bad %>% 
  inner_join(nrc, by = c("term" = "word")) %>% 
  filter(sentiment %in% c("positive", "negative")) %>%
  group_by(sentiment) %>%
  summarise(total_count = sum(count))

plutchik_bad_plot = ggplot(plutchik_bad, aes(sentiment, total_count, fill = sentiment)) + geom_bar(stat = "identity") + ylim(0, 80000) + theme(axis.title.x = element_blank(), axis.title.y= element_blank(),legend.position = "none")

plot_grid(plutchik_good_plot, plutchik_bad_plot, labels = c("Good", "Bad"), label_size = 12, label_x = 0.5, scale = 0.7)

#ggsave("../figs/sentiment_positive_negative.png")
```
Proportion of positive and negative sentiment for good and bad hosts is similar, however, amount of emotionally colored words is considerably higher for good hosts. This suggests that just a longer write up with the same amount of emotional intensity might do the trick for "bad" hosts. Same conclusion holds true, when we consider distinct categories based on Plutchik's wheel of emotions. In terms of emotional intensity, both groups show the same pattern. It suggests that host experiment little with emotion and hold to the standard descriptions. Given overall positive nature of emotions in the narrative, it might be useful to further explore how going beyond the limit of standard emotional level one can alter performance on Airbnb.

```{r}
plutchik_good = tidy_format_good %>% 
  inner_join(nrc, by = c("term" = "word")) %>% 
  filter(!sentiment %in% c("positive", "negative")) %>%
  group_by(sentiment) %>%
  summarise(total_count = sum(count))

plutchik_good_plot = ggplot(plutchik_good, aes(sentiment, total_count, fill = sentiment))+ geom_bar(stat = "identity") + ylim(0, 35000) +  theme(axis.title.x = element_blank(), axis.title.y= element_blank(),axis.text.x = element_text(angle = 90),legend.position = "none")

plutchik_bad = tidy_format_bad %>% 
  inner_join(nrc, by = c("term" = "word")) %>% 
  filter(!sentiment %in% c("positive", "negative")) %>%
  group_by(sentiment) %>%
  summarise(total_count = sum(count))

plutchik_bad_plot = ggplot(plutchik_bad, aes(sentiment, total_count, fill = sentiment)) + geom_bar(stat = "identity") + ylim(0, 35000) + theme(axis.title.x = element_blank(), axis.title.y= element_blank(),axis.text.x = element_text(angle = 90),legend.position = "none")

plot_grid(plutchik_good_plot, plutchik_bad_plot, labels = c("Good", "Bad"), label_size = 12, label_x = 0.5, scale = 0.7)

#ggsave("../figs/sentiment_plutchik.png")
```
Another perspective is to look at emotions with "bing" library, observing the same picture, but document-wise. 

```{r warning=FALSE, message=FALSE}
lexicon3 = get_sentiments('bing')

bing_pos_neg_polarity_bad = tidy_format_bad %>%
  inner_join(lexicon3, by = c("term" = "word")) %>%
  count(document, term, sentiment, wt = count) %>%
  spread(sentiment, n, fill = 0) %>%
  mutate(polarity = positive - negative) %>%
  mutate(positive_negative = ifelse(polarity > 0, "positive", "negative"))

polarity_plot_bad = ggplot(bing_pos_neg_polarity_bad, aes(reorder(document, polarity), polarity, fill = positive_negative)) + geom_col() + ggtitle("Polarity - Bad Listings")  + xlab("Listings") +theme(axis.text.x = element_text(angle = 90, vjust = -0.1, size = 2)) + ylim(-40, 100) + theme(axis.text.x = element_blank(), axis.title.y= element_blank(),legend.position = "none")

bing_pos_neg_polarity_good = tidy_format_good %>%
  inner_join(lexicon3, by = c("term" = "word")) %>%
  count(document, term, sentiment, wt = count) %>%
  spread(sentiment, n, fill = 0) %>%
  mutate(polarity = positive - negative) %>%
  mutate(positive_negative = ifelse(polarity > 0, "positive", "negative"))

polarity_plot_good = ggplot(bing_pos_neg_polarity_good, aes(reorder(document, polarity), polarity, fill = positive_negative)) + geom_col() + ggtitle("Polarity - Good Listings")  + xlab("Listings") +theme(axis.text.x = element_text(angle = 90, vjust = -0.1, size = 2)) + ylim(-40, 100) + theme(axis.text.x = element_blank(), axis.title.y= element_blank(),legend.position = "none")

plot_grid(polarity_plot_bad, polarity_plot_good)

#ggsave("../figs/polarity plot.png")

```

Per document view helps to confidently conclude that it is no the sweetness of message that characterizes a successful write up, and the assumption that successful listings are purely more positive is wrong. It is not the polarity of emotion but amount of emotion drives success.

# Conclusion.

Most people think that business improvement come with additional financial investment. We conducted the analysis that offers tips on how to improve Airbnb performance for free - by writing a great description of your apartment. Here are the tips we discovered.

**What you should do to create a great description of your apartment on Airbnb.**

1. Write more across all textual categories, don't ignore optional fields. Your overall listing should contain between 2500 and 3500 words to be successful.
2. Write a description of 1000 words.
3. Do not rely on exclamation marks to drive attention, this is not what best hosts do to differentiate.
4. If you want to skip a category, skip "about host category".
5. Make it person openness to "questions".
6. Use proper English and standard keyboard.
7. Mention social clues (such as membership and charity) and fancy notions (such as "manor" instead of "house")
8. Add emotion by adding more textual description, not by short and excessively "sweet"" messages.

__________

References

1. Julia Silge, David Robinson. Text Mining with R. 2018. https://www.tidytextmining.com 
2. Text Mining Tutorial. https://www.kaggle.com/rtatman/nlp-in-r-topic-modelling 
3. Debbie Liske. Tidy Sentiment Analysis in R. 2018. https://www.datacamp.com/community/tutorials/sentiment-analysis-R



